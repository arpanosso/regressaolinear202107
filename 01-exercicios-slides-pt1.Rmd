```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Pacotes

```{r, message=FALSE, warning=FALSE}
library(broom)
library(readxl)
library(janitor)
library(MASS)
library(lime)
library(GGally)
library(car)
library(ISLR)
library(tidymodels)
library(tidyverse)
```



## Os dados

```{r}
# cars
dplyr::glimpse(cars)
ggplot2::ggplot(cars) + 
  ggplot2::geom_point(ggplot2::aes(x = speed, y = dist))
```

## ajuste de uma regressão linear simples

```{r}
melhor_reta <- lm(dist ~ speed, data = cars)
```


```{r}
# http://www.danieldsjoberg.com/gtsummary/
library(gtsummary)
gtsummary::tbl_regression(melhor_reta)
summary.lm(melhor_reta)
```



## tabela com as predições junto

```{r}
cars_com_predicoes <- broom::augment(melhor_reta)
dplyr::glimpse(cars_com_predicoes)
```

## Gráfico com a reta ajustada
```{r}
ggplot2::ggplot(cars_com_predicoes) + 
  ggplot2::geom_point(ggplot2::aes(x = speed, y = dist)) +
  ggplot2::geom_line(ggplot2::aes(x = speed, y = .fitted))
```



## Exercício 1

Calcule o EQM da melhor reta e compare com a saída do `summary(melhor_reta)`.

```{r}
# dicas:
# yh é o y chapéu (ou valor ajustado). O nome da coluna retornado pelo augment() para o yh é o .fitted
# EQM = mean((y - yh)^2).
y <- cars_com_predicoes$dist
yh <- cars_com_predicoes$.fitted
EQM <- mean((y - yh)^2)
EQM <- (1/length(y) * sum((y-yh)^2))^.5 
summary((melhor_reta))
```

```{r}
summary(melhor_reta) # compare o resultado obtido com essa saída
```



## Exercício 2 

calcule beta0 e beta1

```{r}
x <- cars$speed
y <- cars$dist

xbarra <- mean(x) #média de X
ybarra <- mean(y) #média de y

beta1 <- sum((x-xbarra)*(y-ybarra))/sum((x-xbarra)^2)
beta1
beta0 <- ybarra - beta1*xbarra
beta0
```





## Exercício 3

Tire as informações do objeto `melhor_reta` para decidir se speed está associado com dist. Use a função `summary()`.

```{r}
resumo_melhor_reta <- summary(melhor_reta)
resumo_melhor_reta$coefficients[1]  #beta0
resumo_melhor_reta$coefficients[2]  #beta1
resumo_melhor_reta$r.squared
resumo_melhor_reta$adj.r.squared
```

## Exercício 4 

Interprete o parâmetro `speed` (beta 1).

```{r}

```


## Exercício 5
Calcule o R2 para a `melhor reta` e depois compare com o valor da saída do `summary()`.

```{r}
r2 <- 1-sum((y-yh)^2)/sum((y-ybarra)^2)
summary(melhor_reta)
```


## Exercício 6

Calcule o R2 ajustado para a `melhor reta` e depois compare com o valor da saída do `summary()`.

```{r}
N <- length(y)
r2aj <- 1-sum((y-yh)^2)/sum((y-ybarra)^2)*(N-1)/(N-2)
```


## Exercício 7

Estude os gráficos que saem do `plot(melhor_reta)`. Procure por outliers.

```{r}
plot(melhor_reta)
```


## Exercício 8

Dados para o exercício: Credit.

- Balance (variável resposta): Saldo no Cartão de Crédito
- Gender (variável explicativa): Masculino ou Feminino

```{r}
glimpse(Credit)
```

Interprete os parametros do modelo abaixo

```{r}
modelo_balance <- lm(Balance ~ Gender, data = Credit)
summary(modelo_balance)
```



## Exercício 9

Calcule as médias de `Balance` para cada `Gender`. Compare os resultados com o exercício anterior.

```{r}

```


## Exercício 10

Explore como usar a função model.matrix(). Use a função `model.matrix()` no lugar de `lm()` do exercício 8 e veja sua saída.

```{r}

```


## Exercício 11

Repita os exercícios 8, 9 e 10, mas agora usando Ethnicity no lugar de Gender.

```{r}

```


## Exercício 12

Crie um boxplot de Balance para cada Ethnicity e avalie se a análise visual é compatível com o que os valores-p indicam.

```{r}
Credit %>%
  ggplot() +
  geom_boxplot(aes(x = Balance, y = Ethnicity, fill = Ethnicity))
```


## Exercício 13: Use os dados simulados `y_x` abaixo:

**dados para o exercício**

```{r}
set.seed(1)
y_x <- tibble(
  x = runif(60),
  y = 10 + 0.5*log(x) + rnorm(30, sd = 0.1)
) %>%
  mutate(
    x2 = log(x)
  )

ggplot(y_x) + geom_point(aes(x = x2, y = y))
```

Use `lm()` para ajustar os seguintes modelos:

1) y ~ x, data = y_x
2) y ~ log10(x), data = y_x

Avalie qual modelo é melhor quanto ao EQM e quanto ao R^2.

```{r}
modelo_lin <- 
modelo_log <- 

summary(modelo_log)
summary(modelo_lin)
```


## Exercício 14 

**dados para o exercício:**

```{r}
set.seed(1)
y_x_poly <- tibble(
  x = runif(30, 0, 20),
  y = 500 + 0.4 * (x-10)^3 + rnorm(30, sd = 50)
)
```

Explore a saída de model.matrix() e lm() utlizando as fórmulas:

a) `y ~ x`
b) `y ~ x + I(x^2) + I(x^3)`
c) `y ~ poly(x, 2, raw = TRUE)`
d) `y ~ poly(x, 3, raw = TRUE)`

```{r}
# Resolução do item a)
a_mm <- model.matrix(y ~ x, data = y_x_poly)
a_lm <- model.matrix(y ~ x, data = y_x_poly)
summary(a_lm)
```

```{r}
# Item b)
b_mm <- 
b_lm <-
summary(b_lm)
```

```{r}
# Item c)
c_mm <- 
c_lm <-
summary(c_lm)
```

```{r}
# Item d)
d_mm <- 
d_lm <-
summary(d_lm)
```

Compare o número de parâmetros com o número de colunas. Qual conclusão?









